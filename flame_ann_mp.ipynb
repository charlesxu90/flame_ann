{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f1a7a5-7e40-4fb9-9ad4-5c9ab84891f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class FlameLoss(_Loss):\n",
    "    __constants__ = ['reduction']\n",
    "\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = 'sum') -> None:\n",
    "        super(FlameLoss, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        return torch.sum((target + 1) * (input - target) ** 2)\n",
    "\n",
    "\n",
    "def create_model(n_input, n_output, layers, device='cpu'):\n",
    "    modules = []\n",
    "\n",
    "    # add first hidden layer (and input layer)\n",
    "    modules.append(torch.nn.Linear(n_input, layers[0]))\n",
    "    modules.append(torch.nn.LeakyReLU())\n",
    "\n",
    "    for i in range(1, len(layers)):\n",
    "        modules.append(torch.nn.Linear(layers[i-1], layers[i]))\n",
    "        modules.append(torch.nn.LeakyReLU())\n",
    "\n",
    "    # add output layer\n",
    "    modules.append(torch.nn.Linear(layers[-1], n_output))\n",
    "\n",
    "    model = torch.nn.Sequential(*modules).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test, device='cpu',\n",
    "          n_epoch=100, lr=0.01, decayRate=0.96, BATCH_SIZE=64):\n",
    "    \n",
    "    # Process training data\n",
    "    torch.manual_seed(1)    # reproducible\n",
    "    train_dataset = Data.TensorDataset(X_train, y_train)\n",
    "    loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=False, )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, decayRate)  # lr*gamma^step\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        for step, (batch_x, batch_y) in enumerate(loader):\n",
    "            b_x = Variable(batch_x).to(device)\n",
    "            b_y = Variable(batch_y).to(device)\n",
    "\n",
    "            y_pred = model(b_x.float())\n",
    "            loss = FlameLoss()(y_pred, b_y.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        lr_decay.step()\n",
    "\n",
    "    # evaluate model:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test.float())\n",
    "        mseLoss = torch.nn.MSELoss(reduction='sum')(y_pred, y_test.float())\n",
    "\n",
    "    y_err = (y_pred-y_test).cpu().data.numpy()\n",
    "    std_err = np.abs(y_err).max(axis=0)   # CO_err, CO2_err\n",
    "    return mseLoss, std_err[0], std_err[1]\n",
    "\n",
    "\n",
    "def dl_modeling(X_train, y_train, X_test, y_test, layers, n_epoch=100):\n",
    "    model = create_model(X_train.shape[1], y_train.shape[1], layers)\n",
    "    return train(model, X_train, y_train, X_test, y_test, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa02b8-7d79-452f-abbc-8bd5e3122589",
   "metadata": {},
   "source": [
    "## Create train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe65ea0-1012-46fe-9f7c-0467066e859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "save_dir = \"/home/xiaopeng/Desktop/Flame_ann/\"\n",
    "df_all_norm = pd.read_pickle(save_dir + \"data/train1_norm.pkl\")  # reload unresampled\n",
    "y = df_all_norm[[\"CO\", \"CO2\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all_norm, y, test_size=0.2, random_state=123)\n",
    "X_train.to_pickle(\"data/train1_train.pkl\")\n",
    "X_test.to_pickle(\"data/train1_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff5369-35bc-4905-a180-e794e16f7b86",
   "metadata": {},
   "source": [
    "## CPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68a0caa8-3306-43f7-9a7b-89f51b865586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time = 2021-11-10 15:58:10.440823\n",
      "10\t10\t10\t7.0500\t0.0946\t0.1360\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(save_dir + \"data/train1_train.pkl\")  # reload unresampled\n",
    "df_test = pd.read_pickle(save_dir + \"data/train1_test.pkl\")  # reload unresampled\n",
    "\n",
    "\n",
    "X_train = torch.tensor(df_train[[\"CO+CO2\", \"N2\"]].values, device='cpu')\n",
    "y_train = torch.tensor(df_train[[\"CO\", \"CO2\"]].values, device='cpu')\n",
    "X_test = torch.tensor(df_test[[\"CO+CO2\", \"N2\"]].values, device='cpu')\n",
    "y_test = torch.tensor(df_test[[\"CO\", \"CO2\"]].values, device='cpu')\n",
    "\n",
    "nodes = [10, 10, 10]\n",
    "loss, CO_err, CO2_err = dl_modeling(X_train, y_train, X_test, y_test, nodes, n_epoch=10)\n",
    "node_str = '\\t'.join([str(x) for x in nodes])\n",
    "print(f\"{node_str}\\t{loss:.4f}\\t{CO_err:.4f}\\t{CO2_err:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e24b3d-f701-402f-a965-2198cf924ab1",
   "metadata": {},
   "source": [
    "## Generate shell scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22e41cf4-11c0-4c14-bb5f-3e4ae03ab97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def gen_2layer(save_dir, layer1, layer2, n_epoch=100, split_size=100):\n",
    "    \"\"\"\n",
    "    :param save_dir: str. Path to save tuning results\n",
    "    :param layer1: list. Number of nodes in the first layer\n",
    "    :param layer2: list. Number of nodes in the second layer\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    split = 1\n",
    "    for i2 in range(len(layer2)):\n",
    "        for i1 in range(len(layer1)):\n",
    "            if counter >= split_size:   # split of 200 runs\n",
    "                counter = 0\n",
    "                split += 1\n",
    "                if 'file' in locals():\n",
    "                    file.close()\n",
    "            if counter == 0:\n",
    "                file = open(save_dir + f\"tune_model/run_Flame_ann_tune_2layer_{split}.sh\", \"w\")\n",
    "                file.write(\"#!/bin/bash\\n\")\n",
    "                file.write(f\"data_dir={save_dir}data/\\n\")\n",
    "                file.write(f\"epochs={n_epoch}\\n\")\n",
    "\n",
    "            file.write(f\"python flame_ann_1cpu.py --data_dir $data_dir --epochs \"\n",
    "                       + f\"$epochs --nodes {layer1[i1]} {layer2[i2]} \"\n",
    "                       + f\">2l-{layer1[i1]}_{layer2[i2]}.out\\n\")\n",
    "            counter += 1\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def gen_3layer(save_dir, layer1, layer2, layer3, n_epoch=100, split_size=100):\n",
    "    \"\"\"\n",
    "    :param save_dir: str. Path to save tuning results\n",
    "    :param layer1: list. Number of nodes in the 1st layer\n",
    "    :param layer2: list. Number of nodes in the 2nd layer\n",
    "    :param layer3: list. Number of nodes in the 3rd layer\n",
    "    :param n_epoch: int. epochs, default 100\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    split = 1\n",
    "    for i3 in range(len(layer3)):\n",
    "        for i2 in range(len(layer2)):\n",
    "            for i1 in range(len(layer1)):\n",
    "                if counter >= split_size:   # each split of 200 runs\n",
    "                    counter = 0\n",
    "                    split += 1\n",
    "                    if 'file' in locals():\n",
    "                        file.close()\n",
    "                if counter == 0:\n",
    "                    file = open(save_dir + f\"tune_model/run_Flame_ann_tune_3layer_{split}.sh\", \"w\")\n",
    "                    file.write(\"#!/bin/bash\\n\")\n",
    "                    file.write(f\"data_dir={save_dir}data/\\n\")\n",
    "                    file.write(f\"epochs={n_epoch}\\n\")\n",
    "\n",
    "                file.write(f\"python flame_ann_1cpu.py --data_dir $data_dir --epochs \"\n",
    "                           + f\"$epochs --nodes {layer1[i1]} {layer2[i2]} {layer3[i3]} \"\n",
    "                           + f\">3l-{layer1[i1]}_{layer2[i2]}_{layer3[i3]}.out\\n\")\n",
    "                counter += 1\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def gen_4layer(save_dir, layer1, layer2, layer3, layer4, n_epoch=100, split_size=100):\n",
    "    \"\"\"\n",
    "    :param save_dir: str. Path to save tuning results\n",
    "    :param layer1: list. Number of nodes in the 1st layer\n",
    "    :param layer2: list. Number of nodes in the 2nd layer\n",
    "    :param layer3: list. Number of nodes in the 3rd layer\n",
    "    :param layer4: list. Number of nodes in the 4th layer\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    split = 1\n",
    "    for i4 in range(len(layer4)):\n",
    "        for i3 in range(len(layer3)):\n",
    "            for i2 in range(len(layer2)):\n",
    "                for i1 in range(len(layer1)):\n",
    "                    if counter >= split_size:   # each split of 200 runs\n",
    "                        counter = 0\n",
    "                        split += 1\n",
    "                        if 'file' in locals():\n",
    "                            file.close()\n",
    "                    if counter == 0:\n",
    "                        file = open(save_dir + f\"tune_model/run_Flame_ann_tune_4layer_{split}.sh\", \"w\")\n",
    "                        file.write(\"#!/bin/bash\\n\")\n",
    "                        file.write(f\"data_dir={save_dir}data/\\n\")\n",
    "                        file.write(f\"epochs={n_epoch}\\n\")\n",
    "\n",
    "                    file.write(f\"python flame_ann_1cpu.py --data_dir $data_dir --epochs \"\n",
    "                               + f\"$epochs --nodes {layer1[i1]} {layer2[i2]} {layer3[i3]} {layer4[i4]} \"\n",
    "                               + f\">4l-{layer1[i1]}_{layer2[i2]}_{layer3[i3]}_{layer4[i4]}.out\\n\")\n",
    "                    counter += 1\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "319ecbaf-5635-44ca-833d-8b4c471e1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=\"/home/xiaopeng/Desktop/Flame_ann/\"\n",
    "                                                      # if not test\n",
    "layer1 = [5, 10, 20, 40, 80, 160]\n",
    "layer2 = [5, 10, 20, 40, 80]\n",
    "layer3 = [5, 10, 20, 40, 80]\n",
    "layer4 = [5, 10, 20, 40]\n",
    "\n",
    "gen_2layer(folder_path, layer1, layer2, n_epoch=100)\n",
    "gen_3layer(save_dir, layer1, layer2, layer3, n_epoch=100)\n",
    "gen_4layer(save_dir, layer1, layer2, layer3, layer4, n_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0df690-353f-41c5-9560-498ae7ab11a7",
   "metadata": {},
   "source": [
    "### Contents of sbatch scripts (to run on ibex)\n",
    "Prefix contents\n",
    "\n",
    "```python\n",
    "#!/bin/bash\n",
    "#SBATCH --time=4:00:00\n",
    "#SBATCH --cpus-per-task=60\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --partition=batch\n",
    "#SBATCH --job-name=2layer\n",
    "#SBATCH --output=./%x-%j-slurm.out\n",
    "#SBATCH --error=./%x-%j-slurm.err\n",
    "\n",
    "start_time=$(date +\"%T\")\n",
    "echo \"Start time: $start_time\"\n",
    "\n",
    "data_dir=/home/xux/work/Flame_ann/data/\n",
    "epochs=100\n",
    "```\n",
    "\n",
    "Suffix contents\n",
    "```python\n",
    "finish_time=$(date +\"%T\")\n",
    "echo \"Finish time: $finish_time\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63272c0-f2fa-4deb-a256-b7a7a04bc80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
